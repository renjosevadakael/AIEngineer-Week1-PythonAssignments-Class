# 📦 Step 1: Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# 📂 Step 2: Load the Dataset
data = pd.read_csv("your_dataset.csv")  # Replace with your actual path

# 🧮 Step 3: Define Features and Target
X = data[['Feature1', 'Feature2']]  # Use one or more features
y = data['Target']  # The value you want to predict

# ✂️ Step 4: Split the Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 🧠 Step 5: Train the Model
model = LinearRegression()
model.fit(X_train, y_train)

# 📈 Step 6: View Model Parameters
print(f"Intercept (B0): {model.intercept_:.2f}")
print(f"Coefficients (B1, B2...): {model.coef_}")
print("Model Equation:")
print(f"y = {model.intercept_:.2f} + " + " + ".join([f"{coef:.2f}*{col}" for coef, col in zip(model.coef_, X.columns)]))

# 🔮 Step 7: Make Predictions
y_pred = model.predict(X_test)

# 🧪 Step 8: Evaluate the Model
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
print("\nModel Evaluation:")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R² Score: {r2:.2f}")

# 📊 Step 9: Visualize Results (Simple Regression Only)
if X.shape[1] == 1:
    plt.scatter(X_test, y_test, color='blue', label='Actual')
    plt.plot(X_test, y_pred, color='red', label='Predicted')
    plt.xlabel(X.columns[0])
    plt.ylabel('Target')
    plt.legend()
    plt.tight_layout()
    plt.show()

# 🧾 Step 10: Predict New Values (Optional)
new_data = pd.DataFrame([[value1, value2]], columns=X.columns)  # Replace with actual values
new_prediction = model.predict(new_data)[0]
print(f"\nPredicted value for input {new_data.values.tolist()[0]}: {new_prediction:.2f} ± {rmse:.2f}")